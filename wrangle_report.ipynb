{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wrangle_report\n",
    "by ANDREW KIBIWOTT \n",
    "udacity project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Data Wrangling (Gather, Assess and Clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "August  22, 2022 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: Wrangle Twitter Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Table of Contents\n",
    "\n",
    "Introduction\n",
    "\n",
    "Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "There are three datasets used for this project.\n",
    "\n",
    "#### Dataset 1 - WeRateDogs Twitter Archive Dataset\n",
    "\n",
    "The WeRateDogs Twitter archive dataset used contains basic tweet data for almost 2400 tweets. The WeRateDogs twitter page is a page that shares beautiful pictures of different breeds of dogs and rates them using a unique measure where the numerator is always higher than 10 (the denominator).\n",
    "For example, 13/10. \n",
    "\n",
    "The columns of the dataset are listed below with their respective significance.\n",
    "\n",
    "tweet_id - unique id of the tweet\n",
    "\n",
    "timestamp - date and time of original tweet\n",
    "\n",
    "source - source of the tweet (phone and it's url)\n",
    "\n",
    "text - All text shared in tweet\n",
    "\n",
    "in_reply_to_status_id - id of the status of a reply\n",
    "\n",
    "in_reply_to_user_id - user id of a reply\n",
    "\n",
    "retweeted_status_id - status id of a retweet\n",
    "\n",
    "retweeted_status_user_id - user id of retweeted status\n",
    "\n",
    "retweeted_status_timestamp - timestamp of retweeted status\n",
    "\n",
    "expanded_urls - url with tweet id\n",
    "\n",
    "rating_numerator = ratings of dog (numerator)\n",
    "\n",
    "rating_denominator = ratings of dog (denominator)\n",
    "\n",
    "name - name of dog\n",
    "\n",
    "doggo - dog stage\n",
    "\n",
    "pupper - dog stage\n",
    "\n",
    "puppo - dog stage\n",
    "\n",
    "floofer - dog stage\n",
    "\n",
    "\n",
    "\n",
    "#### Dataset 2 - Twitter API WeRateDogs Dataset\n",
    "\n",
    "We pull retweet count and favorite count data from thid dataset. This will be combined with the Twitter Archive Dataset for a better analysis.\n",
    "                              \n",
    "The dataset columns:\n",
    "\n",
    "tweet_id - unique id of the tweet\n",
    "\n",
    "retweet_count - number of retweets for a unique tweet\n",
    "\n",
    "favorite_count - number of favorites for a unique tweet\n",
    "                              \n",
    "                              \n",
    "                    \n",
    "#### Dataset 3 - Image Predictions Dataset\n",
    "A machine learning model was used to create this prediction dataset. The algorithm is able to predict whether a picture in a specific tweet contains a particular dog breed with varying degrees of accuracy.\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1: Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was gathered from 3 sources:\n",
    "    \n",
    "Twitter Archive Data was downloaded manually (.csv) form the project space. Converted to pandas dataframe as twitter_archive_data.\n",
    "\n",
    "Twitter API data was to be accessed from Twitter but was also made available by Udacity (.txt). It was converted to a Pandas dataframe as twitter_api_data.\n",
    "\n",
    "Image predictions data was pulled using Requests from the Internet (.tsv). It was read into a Pandas dataframe as image_predictions_data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Data Assessment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter_Archive_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### could not use tweeter API ,insted uset the json txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in columns: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls\n",
    "\n",
    "23 rating denominators are not equal to 10\n",
    "\n",
    "So many rating numerators are less than 10 and there are many outrageous numerators\n",
    "\n",
    "Some dogs have no names but have uncharacteristic names given in the name column such as 'a', 'the', 'my' and 'old'\n",
    "\n",
    "'Timestamp' has wrong (string) datatype\n",
    "\n",
    "Source and text info to be dropped\n",
    "\n",
    "Date should be extracted from timestamp column and saved in new column 'date'. Timestamp column should be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter_Api_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Id' column in twitter_api_data and tweet_id contain same data but with different column names. 'id' should be renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image_Predictions_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content (Data) in p1, p2 and p3 have structure issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redundant columns to be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different names of dog stages in individual columns instead of being in a single column\n",
    "\n",
    "The twitter_archive_data and twitter_api_data must be merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copies of all dataframes were made first. This new copies ('twitter_archive', 'twitter_api' and 'image_predictions') were then cleaned. (This is to ensure that original datasets are preserved in case of any major issues during cleaning).\n",
    "\n",
    "Data cleaning was done using the Define, Code and Test framework.\n",
    "\n",
    "Comments were added to codes to make the steps and functions clear to others to reproduce same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All issues identified during Assessment step of Data Wrangling were cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualisation and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangled data was saved in two new csv files.\n",
    "\n",
    "CLeaned twitter_archive and twitter_api datasets were merged into a Master dataset, 'twitter_archive_master.csv'\n",
    "\n",
    "Cleaned Image Predictions Dataset was stored in a new dataset, 'image_predictions_master.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
